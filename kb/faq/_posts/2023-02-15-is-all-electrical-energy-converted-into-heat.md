---
layout: faq
title: Is this true that computers convert all electrical energy into heat?
tags: FAQ
excerpt_separator: <!--more-->
permalink: kb/faq/is-this-true-that-computers-convert-electrical-energy-into-heat
icon: "icons/faq.png"
---
It is true that computers and other electronic devices ultimately convert all of the electrical energy they consume into heat. This is a consequence of the laws of thermodynamics, which dictate that energy cannot be created or destroyed, only transformed from one form to another.

<!--more-->
Further, physics requires that a certain amount of time has to be used in computation. This is a consequence of the Heisenberg Uncertainty Principle, and may not be violated under our current understanding of the laws of physics. Using these two principles (the Landauer bound and the Margolusâ€“Levitin limit), we can determine quite accurately how much heat would be released by a computer that brute-forced a 128-bit cipher. The results are profoundly silly: It's enough to boil the oceans and leave the planet as a charred, smoking ruin.

In a computer or other electronic device, electrical energy is used to power various components such as the CPU, memory, and storage devices. The primary reason why electronic devices generate heat is due to the resistance of the materials used in their construction. When current flows through a material, it encounters resistance, which causes it to dissipate some of its energy as heat. In electronic devices, this resistance is most commonly found in the components that perform computations, such as the CPU, memory, and other integrated circuits.

This heat must be removed from the device in order to prevent the components from overheating and potentially failing. Traditional air cooling methods use fans and heat sinks to transfer heat from the components to the surrounding air, but [immersion cooling]({{ site.baseurl }}/) methods use a [liquid]({{ site.baseurl}}/immersion-cooling/liquid) to more efficiently absorb and remove the heat.

While it is true that all of the electrical energy consumed by a computer is ultimately converted into heat, the amount of heat generated depends on the specific components being used and the tasks being performed. More powerful components or tasks that require more processing power will generate more heat than less powerful components or tasks.
